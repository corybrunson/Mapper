#' Mapper Reference Class (R6)
#' @name MapperRef
#' @aliases Mapper
#' @description `MapperRef` is an \link{R6} class built for parameterizing and computing mappers efficiently.
#' @section Details: To create a new \code{MapperRef} instance object, instantiate the class with the \code{\link[R6:R6Class]{R6 new}} operator. 
#' Instantiation of a \code{MapperRef} objects requires a data matrix, or a function returning one. \cr
#' The primary output of the Mapper method is a simplicial complex. 
#' \cr 
#' The underlying complex does not need to be modified by the user, i.e. is completely maintained by \code{\link{MapperRef}} methods 
#' (e.g. \code{\link{construct_nerve}}, \code{\link{construct_k_skeleton}}, etc.).
#' @section Usage:
#' \preformatted{m = MapperRef$new(data)} 
#' @section Arguments:
#' \itemize{
#'    \item{\strong{data}}: The data, either as a matrix, a 'dist' object, or a function that returns a matrix.
#' }
#' @section Fields:
#' \itemize{
#'   \item{\strong{data}}: The data, as a function. Evaluation returns the data as a matrix.
#'   \item{\strong{filter}}: The filter, as a function. Evaluation returns the filtered data as a matrix.  
#'   \item{\strong{cover}}: The cover (a \code{\link{CoverRef}} derived object). 
#'   \item{\strong{clustering_algorithm}}: The clustering algorithm to use in the pullback.
#'   \item{\strong{measure}}: Distance measure to use to compute distances in ambient space. See \code{use_distance_measure} for more details.     
#'   \item{\strong{pullback}}: Mapping between the sets in the cover (by index) and the vertices (by id).  
#'   \item{\strong{vertices}}: The mapper vertices. 
#'   \item{\strong{simplicial_complex}}: A \code{\link[simplextree:simplextree]{simplex tree}} object.
#' }
#' 
#' @section Methods:
#' \itemize{
#'   \item{\code{\link{use_filter}}: Specifies the filter.}
#'   \item{\code{\link{use_distance_measure}}: Specifies the distance measure.}
#'   \item{\code{\link{use_cover}}: Specifies the cover. Must be a \code{\link{CoverRef}} object.}
#'   \item{\code{\link{use_clustering_algorithm}}: Specifies the algorithm to decompose the pullback.}
#'   \item{\code{\link{construct_pullback}}: Decomposes the preimages into connected components.}
#'   \item{\code{\link{construct_nerve}}: Constructs simplices at a given dimension.}
#'   \item{\code{\link{construct_k_skeleton}}: Constructs the simplicial complex up to a given dimension.}
#'   \item{\code{\link{as_igraph}}: Converts the 1-skeleton to an \code{\link[igraph:igraph]{igraph object}}.}
#'   \item{\code{\link{as_pixiplex}}: Converts the simplicial complex to a \code{\link[pixiplex:pixiplex]{pixiplex object}}.}
#'   \item{\code{\link{exportMapper}}: Exports the core information of the mapper construction.}
#' }
#' @section More information:
#' Full documentation available \href{https://peekxc.github.io/Mapper}{online}.
#' 
#' @return \code{\link{MapperRef}} instance equipped with methods for building the mapper.
#' 
#' @import methods
#' @importFrom Rcpp sourceCpp
#' @author Matt Piekenbrock, \email{matt.piekenbrock@@gmail.com}
#' @encoding UTF-8
#' @references Gurjeet Singh, Facundo MÃ©moli, and Gunnar Carlsson. "Topological methods for the analysis of high dimensional data sets and 3d object recognition." SPBG. 2007.
#' @useDynLib Mapper
#' @examples 
#' data("noisy_circle", package="Mapper")
#' left_pt <- noisy_circle[which.min(noisy_circle[, 1]),]
#' f_x <- matrix(apply(noisy_circle, 1, function(pt) (pt - left_pt)[1]))
#' m <- MapperRef$new()
#' m$use_data(noisy_circle)
#' m$use_filter(f_x)
#' m$use_cover("fixed interval", number_intervals=8L, percent_overlap=50)
#' m$construct_k_skeleton(k = 1)
NULL

#' @export
MapperRef <- R6::R6Class("MapperRef", 
  private = list(
    .data = NULL, 
    .filter = NULL,
    .cover = NULL, 
    .clustering_algorithm = NULL, 
    .measure = "euclidean", 
    .measure_opt = NULL, 
    .pullback=list(),
    .vertices = list(),
    .simplicial_complex = NULL
  ),
  lock_class = FALSE,  ## Feel free to add your own members
  lock_objects = FALSE ## Or change existing ones 
)

## initialize ----
## Initialization method relies on active binding 
MapperRef$set("public", "initialize", function(data = NULL){
  private$.simplicial_complex <- simplextree::simplex_tree()
  self$use_distance_measure(measure = "euclidean")
  self$use_clustering_algorithm(cl = "single", cutoff_method = "continuous")
  if (!missing(data) && !is.null(data)){ self$use_data(data) }
  return(self)
})

## To add a public member function 
## add function ----
MapperRef$set("public", "add_function", function(name, FUN) {
  self[[name]] <- FUN
  environment(self[[name]]) <- environment(self$add_function)
})

## The set index -> (vertex) decomposition mapping.
## pullback ----
MapperRef$set("active", "pullback", 
  function(value){ 
    if (missing(value)){ private$.pullback } 
    else { private$.pullback <- value }
  }
)

## cover ----
## @title Mapper cover
## @name cover
## @description Every \code{\link{MapperRef}} object requires a \code{\link{CoverRef}} object as 
## is \code{cover} member field. In the context of Mapper, a cover is used to discretize the filter 
## space into a partition, which is then used via a \emph{pullback} operation to construct the vertices. \cr 
## \cr 
## The \code{\link{MapperRef}} class makes no restrictions on the cover that is used; only that it fulfills the 
## requirements of being a valid \code{\link{CoverRef}} instance.
## @seealso \code{\link{CoverRef}} 
MapperRef$set("active", "cover", 
  function(value){ #function(fv, type = c("restrained rectangular"), ...)
    if (missing(value)){ private$.cover } 
    else {
      stopifnot(inherits(value, "CoverRef"))
      private$.cover <- value
      invisible(self)
    }
  }
)

## Mapper stores the vertices as a list
## vertices ----
MapperRef$set("active", "vertices", 
  function(value){
    if(missing(value)){
      private$.vertices
    } else {
      private$.vertices <- value
      # stop("`$vertices` is read-only. To update the vertex membership, use the 'compute_vertices' function.", call. = FALSE)
    }
  }  
)

## simplicial_complex ----
## @title Simplicial Complex 
## @name simplicial_complex 
## @description The relational information of the Mapper construction. 
## @details The primary output of the Mapper method is a simplicial complex. With \code{\link{MapperRef}} objects, 
## the simplicial complex is stored as a \code{\link[simplextree]{simplextree}}. 
## \cr 
## The underlying complex does not need to be modified by the user, i.e. is completely maintained by \code{\link{MapperRef}} methods 
## (e.g. \code{\link{construct_nerve}}, \code{\link{construct_k_skeleton}}, etc.).
MapperRef$set("active", "simplicial_complex", 
  function(value){
    if (missing(value)){ private$.simplicial_complex }
    else {
      stopifnot(is(value, "Rcpp_SimplexTree"))
      private$.simplicial_complex <- value 
      # stop("`$simplicial_complex` is read-only. To change the complex, use the objects (simplex tree) methods directly.", call. = FALSE)
    }
  }
)

## clustering_algorithm ----
## Clustering algorithm must be a function that takes as arguments 'pid' and 'idx' 
MapperRef$set("active", "clustering_algorithm", 
  function(value){
    if (missing(value)){ private$.clustering_algorithm }
    else {
      stopifnot(is.function(value))
      stopifnot(all(c("pid", "idx", "self") %in% names(formals(value))))
      private$.clustering_algorithm <- value
    }
  }
)

## data ----
MapperRef$set("active", "data", function(value){
    if (missing(value)){ return(private$.data) }
    else {
      if (is.matrix(value)){
        data_accessor <- function(data_matrix){
          function(idx=NULL){ 
            if (missing(idx)){ return(data_matrix) }
            return(data_matrix[idx,,drop=FALSE]) 
          }
        }
        private$.data <- data_accessor(value)
        attr(private$.data, ".data_type") <- "data_matrix"
      } else if (is(value, "dist")){
        data_accessor <- function(dist_obj){
          function(idx=NULL){ 
            if (missing(idx)){ return(dist_obj) }
            stopifnot(all(idx > 0 & idx <= attr(dist_obj, "Size")))
            return(dist_subset(dist_obj, idx))
          }
        }
        private$.data <- data_accessor(value)
        attr(private$.data, ".data_type") <- "dist"
      } else if (is.function(value)){
        private$.data <- value
        attr(private$.data, ".data_type") <- "function"
      } else {
        stop("X must be either a matrix-coercible object, a function that returns 
              a matrix of coordinates, or a 'dist' object.")
      }
    }
})
              

## The data should be held fixed
## deprecated
# MapperRef$set("active", "X", 
#   function(value){
#     if (missing(value)){ return(private$.data) }
#     else {
#       if (is.matrix(value)){
#         X_acc <- function(data_matrix){
#           function(idx=NULL){ 
#             if (missing(idx)){ return(data_matrix) }
#             return(data_matrix[idx,,drop=FALSE]) 
#           }
#         }
#         private$.data <- X_acc(value)
#       } else if (is.function(value)){
#         private$.data <- value
#       } else {
#         stop("X must be either a matrix or a function that returns a matrix of coordinates.")
#       }
#       # stop("`$X` is read-only. The data points 'X' are specific to a MapperRef object.")
#     }
#   }
# )


## filter ----
## The filter function associated with the Mapper instance
MapperRef$set("active", "filter", 
  function(value){
    if (missing(value)){ return(private$.filter) }
    else {
      # browser()
      if (is.matrix(value)){
        filter_acc <- function(filter_matrix){
          function(idx=NULL){ 
            if (missing(idx) || is.null(idx)){ return(filter_matrix) }
            return(filter_matrix[idx,,drop=FALSE]) 
          }
        }
        private$.filter <- filter_acc(value)
      } else if (is.function(value)){
        private$.filter <- value
      } else {
        stop("Filter must be a matrix of coordinate values or a function that returns a matrix of coordinate values.")
      }
      return(self)
    }
  }
)

## measure ----
## Active binding for the distance measure
MapperRef$set("active", "measure",
    function(value, ...){
      if (missing(value)){ private$.measure }
      else {
        if (is.character(value)){
          stopifnot(tolower(value) %in% tolower(proxy::pr_DB$get_entry_names()))
          private$.measure <- proxy::pr_DB$get_entry(tolower(value))
        } else if (methods::is(value, "proxy_registry_entry")){
          private$.measure <- value
        }
        return(self)
      }
    }
)

## Stores the supported distance measure in the parallelDist package
.PD_dists <- c(
  "bhjattacharyya", "bray", "canberra", "chord", "divergence", "dtw", "euclidean", 
  "fJaccard", "geodesic", "hellinger", "kullback", "mahalanobis", "manhattan",
  "maximum", "minkowski", "podani", "soergel", "wave", "whittaker", "binary", 
  "braun-blanquet", "dice", "fager", "faith", "hamman", "kulczynski1", "kulczynski2",
  "michael", "mountford", "mozley", "ochiai", "phi", "russel", "simple matching", 
  "simpson", "stiles", "tanimoto", "yule", "yule2", "cosine", "hamming"
)

## distance ----
#' @name distance
#' @title Computes pointwise distances
#' @description This function computes distances using the given distance measure. See details. 
#' @param x numeric matrix of points.
#' @param y optional numeric matrix of points to compare to \code{x}. See details.
#' @param ... Other parameters passed to \code{\link[proxy]{dist}}. 
#' @inheritParams proxy::dist
#' @details This function mimicks the \code{\link[proxy:dist]{proxy distance function}}, but 
#' uses the \pkg{parallelDist} package when possible. Specifically, if \pkg{parallelDist} is available, 
#' only \code{x} was supplied (implying all self-pairwise distances are requested), and the 
#' \code{\link{measure}} is supported, then the distances are computed in parallel. Otherwise, the 
#' \pkg{proxy} package's \code{\link[proxy]{dist}} function is called. \cr
#' \cr
#' The convention followed by this function that is each row represents a point, 
#' and each column a dimension.
MapperRef$set("public", "distance", function(x, y = NULL, ...){
  if (is.vector(x)){ x <- as.matrix(x) }
  if (is.vector(y)){ y <- as.matrix(y) }
  stopifnot(is.matrix(x))
  has_pd <- requireNamespace("parallelDist", quietly = TRUE)
  dist_f <- ifelse(has_pd, parallelDist::parallelDist, proxy::dist)
  d_name <- tolower(head(self$measure$names, 1))
  
  ## Use parallelDist package if available
  if (has_pd && (d_name %in% .PD_dists) && (missing(y) || is.null(y))){
    # if (!is.null(private$.measure_opt)){ dist_params <- append(dist_params, private$.measure_opt) }
    do.call(parallelDist::parallelDist, list(x=x, method=d_name))
  } else {
    proxy::dist(x=x,y=y,method=d_name, ...)
  }
})

## distance_subset ----
#' @name distance_subset
#' @title Extract subset of distances 
#' @description Returns the distances between all pairs of points
#' @param idx Indices in the range [1, n]. 
#' @return a \code{\link[stats]{dist}} object. 
MapperRef$set("public", "distance_subset", function(idx){
  if (attr(private$.data, ".data_type") == "dist"){
    return(self$data(idx))
  } else {
    return(self$distance(x=self$data(idx)))
  }
})

## use_data ----
#' @name use_data
#' @title Sets the data
#' @description Sets the data matrix to associate with the mapper.
#' @param data The data to cluster on with mapper. See details. 
#' @param ... additional parameters to pass to the filter function.
#' @details Sets the data for the mapper construction. \code{data} can either be any input accepted
#' by the proxy package or a 'dist' object, 
#' or a function that returns a matrix of coordinate values. \cr
#' \cr
#' Alternatively, if \code{data} can also be a string giving the name of an existing data set listed in \code{data(package="Mapper")}. 
MapperRef$set("public", "use_data", function(data){
  if (is.character(data)){
    stopifnot(data %in% c("noisy_circle", "wvs_us_wave6"))
    self$data <- local({ 
      data("wvs_us_wave6", package="Mapper", envir = environment())
      data <- eval(parse(text=data))
      return(scale(as.matrix(data))) 
    })
  } else {
    ## Let active binding take care of assignment checks
    self$data <- data 
  }
  return(invisible(self))
})

## use_filter ----
#' @name use_filter
#' @title Sets the filter
#' @description Sets the map, or \emph{filter}, to associate with the instance
#' @param filter either the filter name to use, a matrix, or a function. See details. 
#' @param ... additional parameters to pass to the filter function.
#' @details \code{filter} must be either matrix of coordinate values, a function that returns a matrix of 
#' coordinate values, or a string selecting from one of the predefined filters below. \cr
#' \cr 
#' If a matrix is given (or function returning a matrix), the convention here is that each row 
#' represents a point and each column a dimension. \cr
#' \cr
#' Here's a list of the pre-defined filtering methods supported:
#' \itemize{
#'   \item{\strong{PC}}{ Principle components (with \code{\link[stats:prcomp]{prcomp}})}
#'   \item{\strong{IC}}{ Independent components (with \code{\link[fastICA:fastICA]{fastICA}})}
#'   \item{\strong{ECC}}{ Eccentricity (internal, change the norm by passing one of \eqn{p} = [1, 2, Inf])}
#'   \item{\strong{KDE}}{ Kernel Density Estimate (with \code{\link[ks:ks]{kde}})}
#'   \item{\strong{DTM}}{ Distance to measure (with \code{\link[TDA:dtm]{dtm}})}
#'   \item{\strong{MDS}}{ Classic (Metric) Multidimensional Scaling (with \code{\link[stats:cmdscale]{cmdscale}})}
#'   \item{\strong{ISOMAP}}{ Isometric feature mapping (with \code{\link[vegan:isomap]{isomap}})}
#'   \item{\strong{LE}}{ Laplacian Eigenmaps (with \code{\link[geigen:geigen]{geigen}})}
#'   \item{\strong{UMAP}}{ Uniform Manifold Approximation and Projection (with \code{\link[umap:umap]{umap}})}
#' }
#' Nearly all the pre-configured filters essentially call functions in other packages with
#' somewhat reasonable default parameters to perform the mapping. Any parameters supplied to \code{...} 
#' are passed to the corresponding package function linked above, which override any default parameters. 
#' If the package needed to compute the filter is not installed, a prompt is given asking the user 
#' whether they would like to install it. \cr
#' \cr
#' \strong{NOTE:} The predefined filters are meant to be used for exploratory or illustrative purposes only---this function 
#' is \emph{not} meant to act as a comprensive interface to the functions each filter corresponds too.
MapperRef$set("public", "use_filter", function(filter=c("PC", "IC", "ECC", "KDE", "DTM", "MDS", "ISOMAP", "LE", "UMAP"), ...){
  if (is.function(filter)){ private$.filter <- filter } 
  else if (is.matrix(filter)){
    self$filter <- filter
  } else if (is.numeric(filter) && is.vector(filter)){
    self$filter <- matrix(filter, ncol = 1)
  } else if (is.character(filter)){
    filter <- toupper(filter)
    filter_types <- c("PC", "IC", "ECC", "KDE", "DTM", "MDS", "ISOMAP", "LE", "UMAP")
    if (!filter %in% filter_types){
      stop(sprintf("Filter type %s not recognized. Must be one of: %s", filter, paste0(filter_types, collapse=", ")))
    }
    given_params <- list(...)
    require_but_ask <- function(pkg){
      pkg_installed <- requireNamespace(pkg, quietly = TRUE)
      if (!pkg_installed){
        messsage(sprintf("Using this filter requires the package '%s' to be installed.", pkg))
        response <- readline(prompt = "Would you like to install it? y/n: ")
        if (toupper(substr(response, 1, 1)) == "Y"){ install.packages(pkg) }
      }
    }
    make_dist <- function(params, d_name){
      if (is.null(params[[d_name]])){
        has_pd <- requireNamespace("parallelDist", quietly = TRUE)
        dist_f <- ifelse(has_pd, parallelDist::parallelDist, stats::dist)
        params[[d_name]] <- dist_f(self$data(), method=tolower(self$measure))
      }
      return(params)
    }
    
    ## Basic filters
    if (filter == "PC"){
      default_params <- list(x = self$data(), scale. = TRUE, center = TRUE, rank. = 2L)
      params <- modifyList(default_params, given_params)
      res <- do.call(stats::prcomp, params)
      self$filter <- matrix(res$x, ncol = params[["rank."]])  
      # c("mapper_filter", "function")
    }
    else if (filter == "IC"){
      require_but_ask("fastICA")
      default_params <- list(X=self$data(), n.comp=2, method="C", alg.typ="parallel", fun="logcosh")
      params <- modifyList(default_params, given_params)
      res <- do.call(fastICA::fastICA, params)
      self$filter <- matrix(res$S, ncol = params[["n.comp"]]) ## S stores independent components
    } 
    else if (filter == "ECC"){ ## eccentricity
      has_pd <- requireNamespace("parallelDist", quietly = TRUE)
      dist_f <- ifelse(has_pd, parallelDist::parallelDist, stats::dist)
      params <- modifyList(list(p=1), given_params)
      p_str <- c("manhattan", "euclidean", "maximum")[match(params$p, list(1, 2, Inf))]
      if (params$p != Inf) { 
        self$filter <- matrix(colMeans(as.matrix(dist_f(self$data())^(1/params$p))), ncol = 1)
      } else { self$filter <- matrix(apply(as.matrix(dist_f(self$data())), 2, max), ncol = 1) } 
    }
    else if (filter == "KDE"){
      require_but_ask("ks")
      X <- self$data()
      default_params <- list(x = X, eval.points = X, verbose = FALSE)
      if (is.null(given_params[["H"]])){
        H <- if (ncol(X) <= 4L){ ks::Hpi(X) } else { diag(apply(X, 2, stats::bw.nrd0)) }
        default_params[["H"]] <- H
      }
      params <- modifyList(default_params, given_params)
      self$filter <- matrix(do.call(ks::kde, params)$estimate, ncol = 1L)
    } else if (filter == "DTM"){
      require_but_ask("TDA")
      X <- self$data()
      params <- modifyList(list(X=X, Grid=X, m0=0.20, r=2), given_params)
      self$filter <- matrix(do.call(TDA::dtm, params), ncol = 1L)
    } else if (filter == "MDS"){
      require_but_ask("stats")
      given_params <- make_dist(given_params, "d")
      params <- modifyList(list(k=2), given_params)
      self$filter <- matrix(do.call(stats::cmdscale, params), ncol = params[["k"]])
    } else if (filter == "ISOMAP"){
      require_but_ask("vegan")
      given_params <- make_dist(given_params, "dist")
      ## Get the smallest epsilon to make the graph connected
      if (is.null(given_params[["epsilon"]]) && is.null(given_params[["k"]])){
        eps <- max(vegan::spantree(given_params[["dist"]])$dist)
        eps_add <- min(given_params[["dist"]])
        given_params[["epsilon"]] <- eps + eps_add
      }
      params <- modifyList(list(ndim=2), given_params)
      self$filter <- matrix(do.call(vegan::isomap, params)$points, ncol = params[["ndim"]])
    } else if (filter == "LE"){
      require_but_ask("geigen")
      given_params <- make_dist(given_params, "dist")
      params <- modifyList(list(k=2L, sigma=mean(apply(self$data(), 2, stats::bw.nrd0))), given_params)
      W <- as.matrix(exp(-(params[["dist"]]/(params[["sigma"]]))))
      D <- diag(colSums(W))
      L <- D - W
      res <- geigen::geigen(A = L, B = D, symmetric = TRUE, only.values = FALSE)
      self$filter <- res$vector[,seq(2, 2L+(params[["k"]]-1)),drop=FALSE]
    } else if (filter == "UMAP"){
      require_but_ask("umap")
      self$filter <- do.call(umap::umap, list(d=self$data()))$layout
    } else {
      stop(sprintf("Unknown filter: %s", filter))
    }
  } else{
    stop(sprintf("Unknown format of supplied filter. Must be either string, matrix, matrix-producing function, or vector.", filter))
  }
  invisible(self)
})

## use_distance_measure ----
#' @name use_distance_measure
#' @title Assign a distance measure
#' @description Assigns a distance measure to the \code{\link{MapperRef}} instance to use in the clustering algorithm. 
#' @section Usage:
#' \preformatted{ $use_distance_measure(measure, ...) }
#' @section Arguments: 
#' \describe{
#'   \item{\code{measure}}{The distance measure to use (string).}
#'   \item{\code{...}}{Extra parameters passed to the distance function. See details. }
#' }
#' @section Details: Unless the \code{\link[Mapper:use_clustering_algorithm]{clustering_algorithm}} has been replaced by the user, 
#' by default, Mapper requires a notion of distance between objects to be defined in creating the vertices of the construction. 
#' 
#' The distance function is determined based on the supplied \code{measure}. \code{measure} must be one of:
#' \preformatted{["euclidean", "maximum", "manhattan", "canberra", "binary", "minkowski"]}
#' or, if the \pkg{proxy} and \code{\link[parallelDist]{parallelDist}} packages are installed, any name in \code{proxy::pr_DB$get_entry_names()}.\cr
#' \cr
#' Additional parameters passed via \code{...} are passed to either \code{\link[stats]{dist}} (or 
#' \code{\link[parallelDist]{parallelDist}} if installed). 
#' @section Value:
#' The mapper instance, with the measure field assigned. 
#' @examples 
#' data(noisy_circle)
#' m <- MapperRef$new(noisy_circle)
#' m$use_filter(noisy_circle[,1])
#' m$use_cover("fixed interval", number_intervals = 5, percent_overlap = 25)
#' 
#' ## Constructs clusters with euclidean metric (default)
#' m$use_distance_measure("euclidean")
#' m$construct_pullback() 
#' 
#' ## Constructs clusters with p-norm (p = 1)
#' m$use_distance_measure("Minkowski", p = 1L)
#' m$construct_pullback() 
#' 
#' \dontrun{
#' ## To see list of available measures, use:
#' proxy::pr_DB$get_entry_names()
#' }
#' @seealso \code{\link[parallelDist]{parDist}} \code{\link[proxy]{pr_DB}}
MapperRef$set("public", "use_distance_measure", function(measure, ...){
  if (is.character(measure)){
    measure <- tolower(measure)
    possible_measures <- tolower(proxy::pr_DB$get_entry_names())
    stopifnot(measure %in% possible_measures)
    self$measure <- proxy::pr_DB$get_entry(measure)
  } else if (methods::is(measure, "proxy_registry_entry")){
    self$measure <- measure
  } else if (is.function(measure)){
    measure_name <- as.character(match.call()[["measure"]])
    pr_DB$set_entry(FUN = measure, names = measure_name)
    self$measure <- proxy::pr_DB$get_entry(measure_name)
  } else {
    stop("'measure' must be either a string, proxy registry entry, or a function that computes a pairwise distance.")
  }
  if (!missing(...)){ private$.measure_opt <- list(...) }
  invisible(self)
})

## use_cover ----
#' @name use_cover 
#' @title Selects one of the available covering methods to use.  
#' @description 
#' Convenience method to select, parameterize, and construct a cover and associate it with the calling objects \code{cover} field.   
#' @param cover Either a pre-configured cover, or name of the cover to use. 
#' @param ... Additional parameter values to pass to the covering generators initialize method. 
#' @details Every \code{\link{MapperRef}} object requires a \code{\link{CoverRef}} object as 
#' is \code{cover} member field. In the context of Mapper, a cover is used to discretize the filter 
#' space into a partition, which is then used via a \emph{pullback} operation to construct the vertices. \cr 
#' \cr 
#' The \code{\link{MapperRef}} class makes no restrictions on the cover that is used; only that it fulfills the 
#' requirements of being a valid \code{\link{CoverRef}} instance (e.g. a \code{\link{FixedIntervalCover}}), 
#' or one of the cover typenames listed in the \code{\link{covers_available}()}. 
#' If a typename is given, the cover is automatically constructed before being assigned to the \code{$cover} field.  
#' @examples 
#' data(noisy_circle)
#' m <- MapperRef$new(noisy_circle)
#' m$use_filter(noisy_circle[,1])
#' m$use_cover("fixed interval", number_intervals = 5, percent_overlap = 25)
#' 
#' ## Alternative way to specify (and construct) the cover
#' cover <- FixedIntervalCover$new(number_intervals = 5, percent_overlap = 25)
#' cover$construct(filter = m$filter, cache=TRUE) ## cache=TRUE saves the constructed sets
#' m$cover <- cover
MapperRef$set("public", "use_cover", function(cover="fixed interval", ...){
  stopifnot(!is.null(self$filter))
  if (missing(cover)){ cover <- "fixed interval"}
  if (is.character(cover)){
    cover_options <- c("fixed_interval", "restrained_interval", "ball")
    cover <- gsub(pattern="(.*)cover(.*)", replacement="\\1\\2", x=cover)
    cover <- tolower(gsub(x=trimws(cover), pattern="\\s+", replacement ="_")) 
    match_idx <- which.min(adist(cover, cover_options, partial = TRUE, fixed = FALSE, ignore.case = TRUE))
    self$cover <- switch(cover_options[match_idx], 
      "fixed_interval"=FixedIntervalCover$new(...), 
      "restrained_interval"=RestrainedIntervalCover$new(...),
      # "adaptive"=AdaptiveCover$new(...)$construct_cover(self$filter),
      "ball"=BallCover$new(...),
      "indexed_interval"=IndexedCover$new(...),
      stop(sprintf("Unknown cover type: %s, please specify a cover typename listed in `covers_available()`", cover))
    )
  } else if (is(cover, "CoverRef")){
    self$cover <- cover
  } else {
    stop("Unknown type passed to 'cover'; Must be either valid cover or character string.")
  }
  invisible(self)
})
#@param filter_values (n x d) numeric matrix of values giving the results of the map. 

## use_clustering_algorithm ----
#' @name use_clustering_algorithm 
#' @title Sets the clustering algorithm 
#' @description Sets the clustering algorithm used to construct the connected components in the pullback cover.
#' @param cl Either one of the link criteria used in the \code{\link[stats]{hclust}} function (string) or a function. See details.
#' @param cutoff_method Type of heuristic to determine cut value. See details. Ignored is \code{cl} is a function.
#' @param ... Additional parameters passed as defaults to the cutoff method. See details. 
#' @details If \code{cl} is a linkage criterion, a standard hierarchical clustering algorithm is used with suitable default parameters. 
#' If it is a function, it must have a signature compatible with \code{function(pid, idx, self, ...)} where 
#' \code{pid} is the index of the (pullback) set to cluster (see \code{CoverRef}),  
#' \code{idx} are the indices of the points in \code{X} to cluster on, and
#' \code{self} is the \code{MapperRef} instance environment. 
#' \cr
#' The cutoff method may be one of either c("continuous", "histogram"). See \code{\link{cutoff_first_bin}} and \code{\link{cutoff_first_threshold}}
#' for what they each correspond to, respectively. Additional named parameters passed via \code{...} act as defaults to the cutting method chosen. 
#' If not chosen, reasonable defaults are used. \cr 
#' \cr
#' Additional named parameters passed via the dots in \code{$clustering_algorithm} 
#' will taken precedence and override all previously set default settings. 
MapperRef$set("public", "use_clustering_algorithm", 
  function(cl = c("single", "ward.D", "ward.D2", "complete", "average", "mcquitty", "median", "centroid"), 
           cutoff_method = c("continuous", "histogram"),
           ...){
    ## Use a linkage criterion + cutting rule
    default_cutting_params <- list(...)
    if (missing(cl)) { cl <- "single" }
    if (missing(cutoff_method)){ cutoff_method <- "continuous" } 
    if (class(cl) == "character"){
      hclust_opts <- c("single", "ward.D", "ward.D2", "complete", "average", "mcquitty", "median", "centroid")
      if (!cl %in% hclust_opts){ stop(sprint("Unknown linkage method passed. Please use one of (%s). See ?hclust for details.", paste0(hclust_opts, collapse = ", "))) }
      ## Closured representation to substitute default parameters. 
      create_cl <- function(cl, cutoff_method, cut_defaults){
        cutoff_f <- switch(cutoff_method, "histogram"=cutoff_first_bin, "continuous"=cutoff_first_threshold)
        function(pid, idx, self, ...){
          if (is.null(idx) || length(idx) == 0){ return(integer(0L)) }
          if (length(idx) <= 2L){ return(rep(1L, length(idx))); }
          override_params <- list(...)
          
          ## Get distances of subset
          dist_x <- self$distance_subset(idx)
          
          ## Use fastcluster if available 
          has_fc <- requireNamespace("fastcluster", quietly = TRUE)
          cl_f <- ifelse(has_fc, fastcluster::hclust, stats::hclust)
          hcl <- do.call(cl_f, list(d=dist_x, method=cl))
          
          cutoff_params <- if (cutoff_method == "histogram"){ 
            list(hcl = hcl, num_bins = 10L) 
          } else { list(hcl = hcl, threshold = 0.0) }
          cutoff_params <- modifyList(modifyList(cutoff_params, cut_defaults), override_params)
        
          ## Use heuristic cutting value to produce the partitioning
          eps <- do.call(cutoff_f, cutoff_params)
          return(cutree(hcl, h = eps))
        }
      }
      self$clustering_algorithm <- create_cl(cl, cutoff_method, default_cutting_params)
    } else if (is.function(cl)){
      self$clustering_algorithm <- cl
    } else { stop("Invalid parameter type 'cl'") }
    invisible(self)
  }
)

## construct_cover ----
#' @name construct_cover 
#' @title Constructs the cover on the codomain of the map. 
#' @description Executes the clustering algorithm on subsets of \code{X}, 
#' @param index indices of the \code{\link[Mapper:CoverRef]{covers}} \code{index_set}, or \code{NULL}.
#' @param ... additional parameters to pass to the \code{construct} method of the cover.
#' @details Constructs the cover over the codomain of the filter function. 
MapperRef$set("public", "construct_cover", function(index=NULL, ...){
  stopifnot(is.function(self$filter))
  stopifnot(is(self$cover, "CoverRef"))
  invisible(self$cover$construct(self$filter, cache=TRUE)) ## Cache results into sets
  invisible(self) ## Return self
})

## construct_pullback ----
#' @name construct_pullback 
#' @title Constructs the (decomposed) pullback cover. 
#' @description Executes the clustering algorithm on subsets of \code{X} determined by the \code{$cover}. 
#' @param pullback_ids indices of the \code{\link[Mapper:CoverRef]{covers}} \code{index_set}, or \code{NULL}.
#' @param ... additional parameters to pass to the \code{clustering_algorithm}.
#' @details This methods uses the function given by \code{clustering_algorithm} field to 
#' decompose the preimages returned by the \code{cover} member into connected components, which are 
#' stored as \code{vertices}. Indices may be passed to limit which sets are decomposed, otherwise 
#' the sets in the cover all considered.
#' \cr
#' Note that this method removes the \code{vertices} associated with \code{pullback_ids}, but does not 
#' modify the simplicial complex. 
#' @seealso \code{\link{construct_k_skeleton}} \code{\link{construct_nerve}} \code{\link{use_clustering_algorithm}}
MapperRef$set("public", "construct_pullback", function(pullback_ids=NULL, ...){
  stopifnot(is.function(private$.clustering_algorithm))
  pids_supplied <- (!missing(pullback_ids) && !is.null(pullback_ids))
  if (!pids_supplied){
    sets <- if (length(self$cover$sets) == 0) { self$cover$construct(self$filter) } else { self$cover$sets }
    pullback_ids <- names(sets) ## index set
  }
  
  ## If no specific indices given, then the full pullback will be recomputed. 
  ## If so, this resets everything to a valid state.
  if (!pids_supplied || length(private$.pullback) == 0){
    n_sets <- length(pullback_ids)
    self$simplicial_complex$clear()
    self$vertices <- list()
    private$.pullback <- structure(replicate(n_sets, integer(0)), names = pullback_ids)
  }
  
  ## Calculates the preimage at a given index.
  calc_preimage <- function(){
    function(index){ as.vector(unlist(self$cover$construct(self$filter, index)), mode = "integer") }
  }
  
  ## Re-parameterizes clustering algorithm for C++ side. 
  partial_cluster <- function(...){
    extra <- list(...)
    function(pid, idx){ do.call(self$clustering_algorithm, append(list(pid, idx, self), extra)) }
  }
  
  ## Perform the decomposition, modifying the vertices as a result. 
  ## The pullback is also modified by reference here.  
  private$.vertices <- Mapper:::decompose_preimages(
    pullback_ids = as.character(pullback_ids),
    cluster_f = partial_cluster(...), 
    level_set_f = calc_preimage(), 
    vertices = private$.vertices,
    pullback = private$.pullback
  )
  
  ## Return self
  invisible(self)
})

## construct_nerve ----
#' @name construct_nerve 
#' @title Compute the nerve of the cover. 
#' @description Computes (or updates) the k-simplices composing the Mapper, where k >= 0. 
#' @param k The order of the simplices to construct. See details.  
#' @param indices (n x k) matrix of indices of the covers index set to update.
#' @param min_weight minimum intersection size to consider as a simplex. Defaults to 1.
#' @details Compared to \code{construct_k_skeleton}, this method \emph{only} intersections 
#' between (k-1) simplices in the complex.
MapperRef$set("public", "construct_nerve", function(k, indices = NULL, min_weight=1L, modify=TRUE){
  stopifnot(length(self$pullback) > 0, length(self$vertices) > 0)
  stopifnot(k == trunc(k), k >= 0)
  idx_specified <- (!missing(indices) && !is.null(indices))
  if (idx_specified){
    stopifnot(is.matrix(indices))
    stopifnot(all(unlist(indices) %in% names(self$pullback)))
    stopifnot(k >= 1)
  }

  ## If k==0 is specified, just build the vertices
  stree_ptr <- private$.simplicial_complex$as_XPtr()
  if (k == 0){ 
    if (!modify){ return(as.integer(names(self$vertices))) } 
    build_0_skeleton(as.integer(names(self$vertices)), stree_ptr)
    return(invisible(self))
  }
  
  ## Retrieve the valid level set index pairs to compare. In the worst case, with no cover-specific optimization, 
  ## this may just be all pairwise combinations of LSFI's for the full simplicial complex.
  neighborhood <- if (idx_specified){ indices } else { self$cover$neighborhood(self$filter, k) }
  
  ## If no indices to compute, nothing to do for k > 1. return self invisibly.
  if (is.null(neighborhood)){ return(invisible(self)) }
  
  ## Build the parameter list
  res <- NULL
  if (is.matrix(neighborhood) && length(neighborhood) > 0){
    stopifnot(all(unlist(neighborhood) %in% names(self$pullback)))
    res <- build_k_skeleton_ids(neighborhood, private$.pullback, self$vertices,  stree_ptr, modify, min_weight)
  } else if ("externalptr" %in% class(neighborhood)){
    res <- build_k_skeleton_gen(neighborhood, private$.pullback, self$vertices,  stree_ptr, modify, min_weight)
  } else {
    stop("Unknown set of indices supplied.")
  }
  
  ## If modifying the complex, return the instance invisibly, otherwise return the requested simplices
  if (modify){ return(invisible(self)) }
  else {
    return(res)
  }
})

## construct_k_skeleton ----
#' @name construct_k_skeleton 
#' @title Constructs the k-skeleton
#' @param k the maximal dimension to consider.
#' @description Computes the k-skeleton of the mapper by computing the nerve of the pullback of \code{cover} member.
#' @details 
#' The primary output of the Mapper method is a simplicial complex. With \code{\link{MapperRef}} objects, 
#' the simplicial complex is stored as a \code{\link[simplextree]{simplextree}}. The underlying complex does not need to be modified by the user, i.e. is completely maintained by \code{\link{MapperRef}} methods 
#' (e.g. this method, \code{\link{construct_nerve}}, etc.). \cr 
#' \cr 
#' This function computes the k-skeleton inductively, e.g. by first computing the vertices, 
#' then the edges, etc. up to the dimension specified. A check is performed to ensure the pullback has been decomposed, and 
#' if not, then \code{\link{construct_pullback}} is called. \cr
#' \cr
#' For an algorithmic description of this process, see Singh et. al, section 3.2. 
#' @references Gurjeet Singh, Facundo MÃ©moli, and Gunnar Carlsson. "Topological methods for the analysis of high dimensional data sets and 3d object recognition." SPBG. 2007.
MapperRef$set("public", "construct_k_skeleton", function(k=1L){
  stopifnot(k >= 0)
  self$construct_cover()
  self$construct_pullback()
  for (k_i in seq(0L, k)){ self$construct_nerve(k = k_i) }
  invisible(self)
})

## format ----
## S3-like print override
MapperRef$set("public", "format", function(...){
  #if ("dist" %in% class(private$.data)){ n <- attr(private$.data, "Size") } else { n <- nrow(private$.data) }
  max_k <- length(private$.simplicial_complex$n_simplices)
  if (max_k == 0){ message <- "(empty) Mapper construction" }
  else {
    simplex_info <- sprintf("(%s) (%s)-simplices", paste0(private$.simplicial_complex$n_simplices, collapse = ", "), paste0(0L:(max_k-1L), collapse = ", "))
    message <- paste0("Mapper construction with ", simplex_info)
  }
  if (is(self$cover, "CoverRef")){ message <- append(message, format(self$cover)) }
  return(message)
})

## vis_options ----
#' @name vis_options
#' @title Computes mapper visualization options.
#' @param f numeric function to highlight the simplices with. Defaults to mean filter value. See details.
#' @param vertex_scale function to scale vertex sizes (either linear or logarithmic). Defaults to linear.
#' @param vertex_min minimum vertex size. Default is 10. 
#' @param vertex_min maximum vertex size. Default is 15. 
#' @param embed whether to embed the mapper in a metric space with multidimensional scaling. Defaults to false.
#' @param col_pal color palette to color the simplices by. Defaults to rainbow.
#' @param ... extra parameters passed to \code{\link[simplextree]{plot.simplextree}}.
MapperRef$set("private", "vis_options", function(f=NULL, vertex_scale="linear", vertex_min=10L, vertex_max=15L, embed=FALSE, col_pal="rainbow", ...){
  ## If no function supplied, assume an average filter value for each simplex 
  if (missing(f) || is.null(f)){
    f <- function(simplex){
      idx <- Reduce(intersect, self$vertices[as.character(simplex)])
      mean(rowMeans(self$filter(idx)))
    }
  }
  si_val <- unlist(self$simplicial_complex$ltraverse(simplextree::empty_face, f, "bfs"))[-1]
  
  ## If desired, embed the mapper in a metric space via hausdorff distance. Otherwise 
  ## use a precomputed force-directed layout from igraph
  if (embed){ 
    m_coords <- stats::cmdscale(hausdorff_distance(self), k = 2L)
  } else {
    g <- igraph::graph_from_adjacency_matrix(
      self$simplicial_complex$as_adjacency_matrix(), 
      mode = "undirected"
    )
    m_coords <- igraph::layout.auto(g, dim = 2L)
  }
  
  ## Normalize between 0-1, unless all the same
  normalize <- function(x) { 
    if (all(x == x[1])){ return(rep(1, length(x))) }
    else { (x - min(x))/(max(x) - min(x)) }
  }
  if (missing(vertex_scale)){ vertex_scale <- "linear"}
  
  v_ids <- private$.simplicial_complex$vertices
  vertex_scale <- switch(vertex_scale, "linear"=identity, "log"=log)
  vertex_sizes <- sapply(as.character(v_ids), function(vid) length(self$vertices[[vid]]))
  vertex_radii <- (vertex_max - vertex_min)*normalize(vertex_scale(vertex_sizes)) + vertex_min
  
  ## Return a list of the parameters
  return(list(
    color=bin_color(si_val, col_pal=col_pal, "hex7"),
    size=vertex_radii, 
    label=as.character(v_ids),
    coords=m_coords
  ))
})

## plot ----
#' @name MapperRef.plot
#' @title Plot mapper with base graphics.
#' @param vertex_min minimum vertex cex. Default is 2. 
#' @param vertex_max maximum vertex cex. Default is 4. 
#' @description This function plots the mapper using base \code{\link[graphics]{graphics}}. 
#' The logic to perform the actual plotting is handled by \code{\link[simplextree]{plot.simplextree}}. 
#' This function assumes some traditional visualization parameters often used to visualize the mapper 
#' complex. 
#' @family mapper visualization functions
MapperRef$set("public", "plot", function(f=NULL, vertex_scale="linear", vertex_min=2, vertex_max=4, embed=FALSE, col_pal="rainbow", ...){
  
  ## Get vis options 
  params <- c(as.list(environment()), list(...))
  vis_params <- do.call(private$vis_options, params)
  
  ## Convert to plot.simplextree params
  st_params <- with(vis_params, {
    list(
      coords=coords, 
      text_opt=list(x=coords, labels=label),
      vertex_opt=list(cex=size), 
      color_pal=color
    )
  })
  # modifyList(st_params, list(...))
  
  ## Call the plot.simplextree method
  st_params$x <- self$simplicial_complex
  do.call(simplextree:::plot.Rcpp_SimplexTree, st_params)
})


## as_igraph ----
#' @name as_igraph 
#' @title Exports Mapper as an igraph object.
#' @description Exports the 1-skeleton to a graph using the igraph library.
#' @param vertex_min minimum vertex size. Default is 10. 
#' @param vertex_max maximum vertex size. Default is 25. 
#' @details This method converts the 1-skeleton of the Mapper to an igraph object, and assigns some 
#' default visual properties. Namely, the vertex attributes "color", "size", and "label" and the 
#' edge attribute "color" are assigned. 
#' The vertex colors are colored according on the given color palette (default is rainbow) according 
#' to their mean filter value (see \code{\link{bin_color}}). The vertex sizes are scaled according 
#' to the number of points they contain, scaled by \code{vertex_scale}, and bounded between 
#' (\code{vertex_min}, \code{vertex_max}). The vertex labels are in the format "<id>:<size>".\cr
#' \cr
#' The edges are colored similarly by the average filter value of the points intersecting
#' both nodes they connect too.
#' @family mapper visualization functions
#' @return an igraph object.
MapperRef$set("public", "as_igraph", function(f=NULL, vertex_scale="linear", vertex_min=10L, vertex_max=25L, embed=FALSE, col_pal="rainbow", ...){
  requireNamespace("igraph", quietly = TRUE)
  
  ## Convert 1-skeleton to igraph object 
  am <- private$.simplicial_complex$as_adjacency_matrix()
  colnames(am) <- as.character(private$.simplicial_complex$vertices)
  G <- igraph::graph_from_adjacency_matrix(am, mode = "undirected", add.colnames = NULL) ## NULL makes named vertices
  
  ## Get vis options 
  params <- c(as.list(environment()), list(...))
  vis_params <- do.call(private$vis_options, params)
  
  ## Get 1-skeleton indices 
  dim_idx <- unlist(self$simplicial_complex$ltraverse(length, "bfs")[-1])
  
  ## Assign vis options
  igraph::vertex_attr(G, "color") <- vis_params$color[dim_idx == 1L]
  igraph::vertex_attr(G, "size") <- vis_params$size
  igraph::vertex_attr(G, "label") <- vis_params$label 
  igraph::edge_attr(G, "color") <- vis_params$color[dim_idx == 2L]
  igraph::graph_attr(G, "layout") <- vis_params$coords
  
  ## Return igraph object 
  return(G)
})
  
  
  ## Coloring + aggregation functions
  # agg_val <- function(lst) { sapply(sapply(lst, function(idx){ rowMeans(self$filter(idx)) }), mean) } 
  
  ## Aggregate node filter values
  # v_idx <- match(private$.simplicial_complex$vertices, as.integer(names(self$vertices)))
  # agg_node_val <- agg_val(private$.vertices)
  # igraph::vertex_attr(G, name = "color") <- bin_color(agg_node_val[v_idx], col_pal = col_pal)
  # 
  ## Extract indices in the edges
  # edges <- igraph::as_edgelist(G)
  # edge_idx <- lapply(seq(nrow(edges)), function(i){
  #   vids <- edges[i,]
  #   intersect(private$.vertices[[vids[1]]], private$.vertices[[vids[2]]])
  # })
  # agg_edge_val <- agg_val(edge_idx)
  # igraph::edge_attr(G, name = "color") <- bin_color(agg_edge_val, col_pal = col_pal)
  
  # ## Normalize between 0-1, unless all the same
  # normalize <- function(x) { 
  #   if (all(x == x[1])){ return(rep(1, length(x))) }
  #   else {  (x - min(x))/(max(x) - min(x)) }
  # }
  # if (missing(vertex_scale)){ vertex_scale <- "linear"}
  # vertex_scale <- switch(vertex_scale, "linear"=identity, "log"=log)
  # vertex_sizes <- sapply(private$.vertices, length)
#   igraph::vertex_attr(G, "size") <- (vertex_max - vertex_min)*normalize(vertex_scale(vertex_sizes[v_idx])) + vertex_min
# 
#   ## Fill in labels with id:size
#   v_labels <- cbind(names(private$.vertices)[v_idx], vertex_sizes[v_idx])
#   igraph::vertex_attr(G, "label") <- apply(v_labels, 1, function(x){ paste0(x, collapse = ":") })
#   return(G)
# })

## as_pixiplex ----
#' @name as_pixiplex
#' @title Exports the complex as a pixiplex object.
#' @family mapper visualization functions
#' @description Uses the \pkg{pixiplex} library. 
MapperRef$set("public", "as_pixiplex", function(f=NULL, vertex_scale="linear", vertex_min=5L, vertex_max=15L, embed=FALSE, col_pal="rainbow", ...){
  requireNamespace("pixiplex", quietly = TRUE)
  pp <- pixiplex::pixiplex(private$.simplicial_complex)
  
  ## Get vis options 
  params <- c(as.list(environment()), list(...))
  vis_params <- do.call(private$vis_options, params)
  
  ## Get 1-skeleton indices 
  dim_idx <- unlist(self$simplicial_complex$ltraverse(length, "bfs")[-1])
  
  ## Parameterize the pixiplex object
  pp$nodes$color <- vis_params$color[dim_idx==1L]
  pp$nodes$radius <- vis_params$size
  # pp$links$color <- vis_params$color[dim_idx==2L]
  
  ## Return
  return(pp)
})

# as_upset
# @description Visualizes the mapper as an upset diagram
# @details UpSet is a technique for visualizing set intersections, designed to be a scalable alternative to
# more traditional approaches, e.g. the Venn diagram. Since Mapper is fundamentally a topological means of
# expressing intersections between summaries of the data,
# MapperRef$set("public", "as_upset", function(f){
#   upset_installed <- requireNamespace("UpSetR", quietly = TRUE)
#   stopifnot(upset_installed)
#   x_dim <- dim(m$data())
#   x_groups <- matrix(0L, nrow = x_dim[[1]], ncol = m$simplicial_complex$n_simplices[[1]])
#   vids <- as.character(m$simplicial_complex$vertices)
#   colnames(x_groups) <- paste0("v", vids)
#   for (vid in vids){
#     v_idx <- match(vid, vids)
#     x_groups[m$vertices[[vid]],v_idx] <- 1L
#   }
#   v_len <- sapply(m$vertices, length)
#   v_len_dec <- sort(unname(v_len), decreasing = TRUE)
#   v_idx <- Position(function(x) x >= 0.95, cumsum(v_len_dec)/sum(v_len_dec))
#   top_vids <- names(m$vertices)[order(v_len, decreasing = TRUE)][1:v_idx]
#   avg_v_f <- sapply(vids, function(vid) { mean(rowMeans(m$filter(m$vertices[[vid]]))) })
#   row_col <- bin_color(avg_v_f)[match(top_vids, vids)]
#   # list("matrix_rows, colors = c(Boston = "green", NYC = "navy", LA = "purple"), 
#   # alpha = 0.5)))
#   vids_int <- as.integer(top_vids)
#   
#   
#   ## Color intersections by f
#   res_f <- m$simplicial_complex$ltraverse(empty_face, function(simplex){
#     if (all(simplex %in% vids_int)){
#       list(simplex = simplex, f_val = mean(avg_v_f[match(simplex, vids)])) 
#     }
#   }, type = "dfs") 
#   res_f <- Filter(function(x) { !is.null(x) }, res_f)
#   params <- lapply(res_f, function(el){ 
#     list(query = intersects, 
#          params = as.list(paste0("v", as.character(el$simplex))),
#          color = bin_color(avg_v_f)[match(el$simplex, vids)], 
#          active = FALSE
#     )
#   }) # sapply(params, function(p) unlist(p[[2]]))
#   
#   # queries = list(list(query = intersects, params = list("Drama"), color = "red", active = F)
#   us_df <- as.data.frame(x_groups)
#   meta_data <- data.frame(sets=as.factor(paste0("v", top_vids)))
#   meta_data$cat_id <- as.character(paste0("v", top_vids))
#   id_color_map <- structure(row_col, names=as.character(meta_data$cat_id))
#   UpSetR::upset(data = us_df, nsets = v_idx, 
#                 sets.x.label = "Node size", 
#                 scale.intersections = "identity", 
#                 set.metadata = list(
#                   data=meta_data,
#                   plots=list(list(type="matrix_rows", column="cat_id", colors=id_color_map, alpha=0.5))
#                 )
#   )
#                   
#                 # queries = wut, 
#                 # queries = list(list(query = intersects, params = list("v43"), color = "red", active = F)),
#                 #queries = list(list(query = intersects, params = list("v43", "v37"), color = "red", active = F)), 
#                 mb.ratio = c(0.35, 0.65))
#   sets.bar.color = row_col
#   
# 
#   
# 
# })

## exportMapper ----
#' @name exportMapper
#' @title Exports minimal information about the Mapper
#' @description This function exports a few core characteristics about the mapper complex as a list.
#' @param graph_type export preference on the structure the graph output.
#' @return List with the following members: 
#' \itemize{
#'   \item \emph{vertices} list of the indices of the original data the current vertex intersects with.
#'   \item \emph{graph} some adjacency representation of the mapper graph.
#'   \item \emph{pullback} map connecting the index set of the cover and the vertices.
#' }
#' @details \code{graph_type} must be one of 'adjacency_matrix', 'adjacency_list', or 'edgelist'. 
MapperRef$set("public", "exportMapper", function(graph_type=c("adjacency_matrix", "adjacency_list", "edgelist")){
  result <- list(pullback = private$.pullback, vertices = private$.vertices)
  if (missing(graph_type)){ graph_type <- "adjacency_matrix" }
  result$graph <- switch(graph_type, 
                         "adjacency_matrix"=self$simplicial_complex$as_adjacency_matrix(),
                         "adjacency_list"=self$simplicial_complex$as_adjacency_list(), 
                         "edgelist"=self$simplicial_complex$as_edge_list(), 
                         stop("'graph_type' must be one of: 'adjacency_matrix', 'adjacency_list', 'edgelist'"))
  n_simplices <- self$simplicial_complex$n_simplices
  x_dim <- ncol(self$data())
  z_dim <- ncol(self$filter())
  attr(result, ".summary") <- c(sprintf("Mapper with filter f: %s -> %s",
                                        ifelse(x_dim > 1, sprintf("X^%d", x_dim), "X"),
                                        ifelse(z_dim > 1, sprintf("Z^%d", z_dim), "Z")),
                                format(self$cover))
  class(result) <- "Mapper"
  return(result)
})

